# 2. PARSING

---

## 2.1. Parsers

we may heard of "parser error" or:

- we need to parse this
- after it's parsed
- the parser blows up with this input

the word "parser", as common as, compiler, interpreter, and programming language.

what's parser, according to wikipedia:

- a parser is a software component
- that takes input data (frequently text)
- and builds a data structure (often "parse tree", AST, or other hierarchical structure)
- giving a structural representational of the input
- checking for correct syntax in the process
- often preceded by a separate lexical analyser
  - lexical analyser: creates tokens form the sequence of input characters
  
A parser:

- turns input into a data structure that represents the input
- example in JavaScript

```js
> var input = '{"name": "Mark", "age": 10}';
> var output = JSON.parse(input);
output
{ name: 'Mark', age: 10 }
> output.name
'Mark'
> output.age
10
>
```

- `input` is just some text, a string (in JSON format)
- we pass the `input` to a parser, underlying `JSON.parse` function
- `output` is the data structure that represents the `input`
  - input as a JavaScript object with two fields named `name` and `age`

but we often hear:
 
> "a JSON parser is not the same as a parser for a programming language!, they are differnet!"

actually no, they are NOT different (at least not on a conceptual level)

a JSON parser:

- takes text as input
- builds a data structure that represents the input

this is exactly what parsers of programming languages do. 

The differences?

- for JSON, you can see the data structure when looking at the `input`
- whereas in normal programming language's case:
  - `if ((5 + 2 * 3) == 91) { return computeStuff(input1, input2); }`
  - not immediately can see how it would be represented with a data structure 

additionally:

> "As users of programming languages we seldom get to see or
   interact with the parsed source code, with its internal representation. Lisp programmers are
   the exception to the rule – in Lisp the data structures used to represent the source code are the
   ones used by a Lisp user. The parsed source code is easily accessible as data in the program.
   “Code is data, data is code” is something you hear a lot from Lisp programmers."

- to bring our conceptual understanding of programming language parsers
  - up to the level of our familiarity, intuitiveness with parcers of serialisation languages
  - e.g. `JSON`, `YAML`, `TOML`, `INI`, ...
- we need to understand
  - the data structures parsers produce
  
most interpreters / compilers, the data structure used as the internal representation of the source code:

- syntax tree
- abstract syntax tree a.k.a. AST

```gopher
if (3 * 5 > 10) {
    return "hello";
} else {
    return "goodbye";
}
```

assume:

- we use JavaScript
- have a `MagicLexer`, `MagicParser`
- the AST is built out of JavaScript objects
- the parsing step might produce something like this:

```js
> var input = 'if (3 * 5 > 10) { return "hello"; } else { return "goodbye"; }';
> var tokens = MagicLexer.parse(input);
> MagicParser.parse(tokens);
{
    type: "if-statement",
    condition: {
        type: "operator-expression",
        operator: ">",
        left: {
            type: "operator-expression",
            operator: "*",
            left: { type: "integer-literal", value: 3 },
            right: { type: "integer-literal", value: 5 }
        },
        right: { type: "integer-literal", value: 10 }
    },
    consequence: {
        type: "return-statement",
        returnValue: { type: "string-literal", value: "hello" }
    },
    alternative: {
        type: "return-statement",
        returnValue: { type: "string-literal", value: "goodbye" }
    }
}
```

the AST (the output of the parser), is pretty abstract:

- no parentheses
- no semicolons
- no braces

BUT, it does represent the source code quite accurately.

in short, parsers:

- take source code as input - text or token
- produce a data structure that represents the given source code
- whilst building up the data structure,
  - analyse the input
  - checking that it conforms to the expected structure
  - this process os parsing called "syntactic analysis"

---

## 2.2. Why not a Parser Generator?

- parser generators: `yacc`, `bison`, `ANTLR`
  - they are tools that:
    - when fed with a formal description of a language
    - produce parsers as their output

```note
a formal description of a language -> Parser Generator -> a Parser
```

- Parser Generator
  - input: formal description
  - output: parser
  
the output, parser:

- is set of code that can be compiled/interpreted
- itself fed with source code as input to produce a syntax tree (e.g. AST)

majority of parser generators use "context-free grammar (CFG)" as their input.

- CFG
  - a set of rules
  - that describe how to form correct (valid according to the syntax) sentences in a Language
  
the most common notational formats of CFGs are:

- Backus-Naur Form (BNF)
- Extended Backus-Naur Form (EBNF)

e.g. a part of [full description](https://tomcopeland.blogs.com/EcmaScript.html) of the EcmaScript syntax in BNF:

```bnf
PrimaryExpression ::= "this"
                    | ObjectLiteral
                    | ( "(" Expression ")" )
                    | Identifier
                    | ArrayLiteral
                    | Literal
Literal ::= ( <DECIMAL_LITERAL>
            | <HEX_INTEGER_LITERAL>
            | <STRING_LITERAL>
            | <BOOLEAN_LITERAL>
            | <NULL_LITERAL>
            | <REGULAR_EXPRESSION_LITERAL> )
Identifier ::= <IDENTIFIER_NAME>
ArrayLiteral ::= "[" ( ( Elision )? "]"
                 | ElementList Elision "]"
                 | ( ElementList )? "]" )
ElementList ::= ( Elision )? AssignmentExpression
                ( Elision AssignmentExpression )*
Elision ::= ( "," )+
ObjectLiteral ::= "{" ( PropertyNameAndValueList )? "}"
PropertyNameAndValueList ::= PropertyNameAndValue ( "," PropertyNameAndValue
                                                  | "," )*
PropertyNameAndValue ::= PropertyName ":" AssignmentExpression
PropertyName ::= Identifier
              | <STRING_LITERAL>

              | <DECIMAL_LITERAL>
```

a parser generator take something similar to BNF/EBNF and turn it into compilable C code.

- most of people say we should use parser generator
- mainly very smart computer scientists already resolved a lot of parsing problems
- this is solved problem
- the results of these smart people's work: CFG, BNF, EBNF, parser generator, advanced parsing techniques
- BUT, learning "how to write parser" is meaningful, helpful, and important
  - you'll see
    - benefit of parser generators and their features
    - drawbacks they have
    - the problems they solved
    
> Most people, that recommend using a parser generator, when others want to get started with interpreters and compilers only do so because they’ve written a parser themselves before. They’ve
  seen the problems and solutions available and decided it’s better to use an existing tool for the
  job. And they’re correct - when you want to get something done and are in a production environment, where correctness and robustness are priorities. Of course you shouldn’t try to write
  your own parser then, especially not if you’ve never written one before.

their goals and our goal is different:

- we want to understand how parser works, whereas they already understood
- also it should be fun! 

---

## 2.3. Writing a Parser for the Gopher Programming Language

- two main strategies when parsing a program:
  - top-down parsing: recursive descent parsing, early parsing, predictive parsing
  - bottom-up parsing
 
> "recursive descent parsing" 

we will do this. in particular, it's a "top down operator precedence" parser.
also a.k.a. "Pratt parser", influenced by Vaughan Pratt.

- differences between: top-down or bottom-up parsing:
  - the former starts with constructing root node of the AST
  - and then descends whilst the latter does it the other way around
  - e.g. recursive descent parser, top-down parser:
    - works from the top down
    - recommended for new comer for parsing
    - since it closely mirrors the way we think about ASTs and their construction
    
limitation of current project:

- won't be fastest of all time
- won't have
  - formal proof of its correctness
  - its error-recovery process
  - detection of erroneous syntax won't be bullet proof

will start with "parsing statements":

- `let` statement
- `return` statement

steps:

- when we can parse statements and the basic structure of our parser stands
- we'll look at expressions
- how to parse these
- we extend the parser to make it capable of parsing a large subset of Gopher programming language
- we build up the necessary structures for our AST

---
